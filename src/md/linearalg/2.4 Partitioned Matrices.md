---
tags:
  - mathematics/linear_algebra
---
# 2.4 Partitioned Matrices

## Partitioned Matrices

A key feature of our work with matrices has been the ability to regard a matrix $A$ as a list of column vectors rather than just a rectangular array of numbers. This point of view has been so useful that we wish to consider other partitions of $A$, indicated by horizontal and vertical dividing rules, as in Example 1 below. Partitioned matrices appear in most modern applications of linear algebra because the notation highlights essential structures in matrix analysis, as in the chapter introductory example on aircraft design.

### Example 1

The matrix

$$
A = 
\begin{pmatrix}
3 & 0 & 1 & 5 & 9 & 2 \\
5 & 2 & 4 & 0 & 3 & 1 \\
8 & 6 & 3 & 1 & 7 & 4
\end{pmatrix}
$$  

can also be written as the $2 \times 3$ partitioned (or block) matrix

$$
A = 
\begin{pmatrix}
A_{11} & A_{12} & A_{13} \\
A_{21} & A_{22} & A_{23}
\end{pmatrix}
$$  

where the entries are the blocks (or submatrices):

$$
A_{11} = 
\begin{pmatrix}
3 & 0 & 1 \\
5 & 2 & 4
\end{pmatrix}, \quad
A_{12} = 
\begin{pmatrix}
5 & 9 \\
0 & 3
\end{pmatrix}, \quad
A_{13} = 
\begin{pmatrix}
2 \\
1
\end{pmatrix}
$$  

and

$$
A_{21} = 
\begin{pmatrix}
8 & 6 & 3
\end{pmatrix}, \quad
A_{22} = 
\begin{pmatrix}
1 & 7
\end{pmatrix}, \quad
A_{23} = 
\begin{pmatrix}
4
\end{pmatrix}
$$

### Example 2

When a matrix $A$ appears in a mathematical model of a physical system such as an electrical network, a transportation system, or a large corporation, it may be natural to regard $A$ as a partitioned matrix. For instance, if a microcomputer circuit board consists mainly of three VLSI (very large-scale integrated) microchips, then the matrix for the circuit board might have the general form

$$
A =
\begin{pmatrix}
A_{11} & A_{12} & A_{13} \\
A_{21} & A_{22} & A_{23} \\
A_{31} & A_{32} & A_{33}
\end{pmatrix}
$$  

The submatrices on the “diagonal” of $A$—namely, $A_{11}$, $A_{22}$, and $A_{33}$—concern the three VLSI chips, while the other submatrices depend on the interconnections among those microchips.

## Addition and Scalar Multiplication

If matrices $A$ and $B$ are the same size and are partitioned in exactly the same way, then it is natural to make the same partition of the ordinary matrix sum $A + B$. In this case, each block of $A + B$ is the (matrix) sum of the corresponding blocks of $A$ and $B$. Multiplication of a partitioned matrix by a scalar is also computed block by block.

## Multiplication of Partitioned Matrices

Partitioned matrices can be multiplied by the usual row–column rule as if the block entries were scalars, provided that for a product $AB$, the column partition of $A$ matches the row partition of $B$.

### Example 3

Let

$$
A =
\begin{pmatrix}
2 & 3 & 1 & 0 & 4 \\
1 & 5 & 2 & 3 & 1 \\
0 & 4 & 2 & 7 & 1
\end{pmatrix} = 
\begin{pmatrix}
A_{11} & A_{12} \\
A_{21} & A_{22}
\end{pmatrix}, \quad
B = 
\begin{pmatrix}
6 & 4 \\
2 & 1 \\
3 & 7 \\
1 & 3 \\
5 & 2
\end{pmatrix} = 
\begin{pmatrix}
B_1 \\
B_2
\end{pmatrix}
$$  

The 5 columns of $A$ are partitioned into a set of 3 columns and a set of 2 columns. The 5 rows of $B$ are partitioned similarly. We say that the partitions of $A$ and $B$ are conformable for block multiplication. The ordinary product $AB$ can be written as

$$
AB = 
\begin{pmatrix}
A_{11} & A_{12} \\
A_{21} & A_{22}
\end{pmatrix}
\begin{pmatrix}
B_1 \\
B_2
\end{pmatrix} = 
\begin{pmatrix}
A_{11}B_1 + A_{12}B_2 \\
A_{21}B_1 + A_{22}B_2
\end{pmatrix}
= 
\begin{pmatrix}
5 & 4 \\
6 & 2 \\
2 & 1
\end{pmatrix}
$$  

It is important for each smaller product in the expression for $AB$ to be written with the submatrix from $A$ on the left, since matrix multiplication is not commutative.

For example,

$$
A_{11}B_1 = 
\begin{pmatrix}
2 & 3 & 1 \\
1 & 5 & 2
\end{pmatrix}
\begin{pmatrix}
6 & 4 \\
2 & 1 \\
3 & 7
\end{pmatrix} = 
\begin{pmatrix}
15 & 12 \\
2 & 5
\end{pmatrix}
$$  

and

$$
A_{12}B_2 = 
\begin{pmatrix}
0 & 4 \\
3 & 1
\end{pmatrix}
\begin{pmatrix}
1 & 3 \\
5 & 2
\end{pmatrix} = 
\begin{pmatrix}
20 & 8 \\
8 & 7
\end{pmatrix}
$$  

Thus,

$$
A_{11}B_1 + A_{12}B_2 = 
\begin{pmatrix}
15 & 12 \\
2 & 5
\end{pmatrix}
+ 
\begin{pmatrix}
20 & 8 \\
8 & 7
\end{pmatrix}
= 
\begin{pmatrix}
5 & 4 \\
6 & 2
\end{pmatrix}
$$
